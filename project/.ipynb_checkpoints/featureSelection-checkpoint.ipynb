{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78ccfe9",
   "metadata": {},
   "source": [
    "# Extract features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "##### model\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "import warnings\n",
    "import collections\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# crate a list to add dataframes to\n",
    "awsc_list = list()\n",
    "\n",
    "# list of files\n",
    "files_list = ['../Datasets/flaws_cloudtrail00.json']\n",
    "\n",
    "# Load event names\n",
    "category_file = open(\"../Utils/event_category.json\")\n",
    "event_categories = json.load(category_file)\n",
    "category_file.close()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c04db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "starts_with_di = {\n",
    "    'CreateObject': ['request','create','copy','run','purchase','allocate','import'],\n",
    "    'ModifyExistingResource': ['modify','update','set','tag','deregister','Deprecate','un','reject','register'],\n",
    "    'ListResources' : ['list'],\n",
    "    'Download/UploadObjects': ['getobjects','upload'],\n",
    "    'GetInfo': ['describe','get','search'],\n",
    "    'AssociateResources' : ['associate','put'],\n",
    "    'Login' : ['assume','login','switch','renewrole','renewdelegate'],\n",
    "    'RemovePermissions': ['remove'],\n",
    "    'GrantPermissions': ['add','authorize']\n",
    "\n",
    "}\n",
    "\n",
    "contains_di = {\n",
    "    'Delete': ['delet','terminate','revoke','drop','releaseaddress'] ,\n",
    "    'DisableObjects': ['disabl','stop','cancel','unlink','suspend'],\n",
    "    'EnableObjects': ['enabl','start','invoke','subscribe','test','complete'],\n",
    "    'SensitiveInfo': ['send','accesskey','secretkey','token','invite','exportapi'],\n",
    "    'Logout': ['exit'],\n",
    "    'CreateObject': ['create','copy'],\n",
    "    'ModifyExistingResource': ['failover','change','confirm','promote','reboot','rotate','replace','retire','detach','modify','update','set','tag','deregister','Deprecate','attach','upgrade','wipe','transfer','validate','publish'],\n",
    "    'ListResources' : ['list'],\n",
    "    'Download/UploadObjects': ['getobjects','upload'],\n",
    "    'GetInfo': ['describe','get','view'],\n",
    "    'AssociateResources' : ['associate','put'],\n",
    "    'Login' : ['assume','login','renewrole','sign','forgot'],\n",
    "    'Logout' : ['logout']\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4acd62d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for file in files_list:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.loads(f.read())\n",
    "        \n",
    "        # Append the dataframes\n",
    "        awsc_list.append(pd.DataFrame.from_records(data['Records']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data frames into one \n",
    "awsc = pd.concat(awsc_list).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "awsc[(awsc['eventSource']=='cognito-idp.amazonaws.com')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.json_normalize(awsc['userIdentity']).merge(awsc[['eventTime','eventName','eventSource','awsRegion','errorCode']], left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['userName'] = users['userName'].fillna(users['arn']).fillna(users['invokedBy']) \\\n",
    ".fillna(users['invokedBy']).fillna(users['principalId']).fillna('accountId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users[['eventTime','type','userName','eventName','eventSource','awsRegion','errorCode']]\n",
    "users = users.rename(columns = {'eventTime':'timestamp','userName':'Identifier','eventSource':'TargetService','errorCode':'Error'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f49ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "awsc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791f970",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = []\n",
    "def change_name(name):\n",
    "    if name in event_categories:\n",
    "        return event_categories[name]\n",
    "    for key,value in starts_with_di.items():\n",
    "        for event_name in value:\n",
    "            if name.lower().startswith(event_name):\n",
    "                return key\n",
    "    for key,value in contains_di.items():\n",
    "        for event_name in value:\n",
    "            if event_name in name.lower():\n",
    "                return key\n",
    "    li.append(name)\n",
    "\n",
    "users['eventName'] = users['eventName'].apply(lambda name: change_name(name))\n",
    "\n",
    "# users['eventName'] = pd.DataFrame({'eventName':encoder.fit_transform(users[['eventName']]).toarray().tolist()},)\n",
    "# users = users.join(encoder_df)\n",
    "# users = users.drop('eventName', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e9c91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users['timestamp'] = pd.to_datetime(users['timestamp']).map(pd.Timestamp.timestamp).map(int)\n",
    "users = users.sort_values('timestamp',ascending=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfa44f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_time_df(start,end,minutes,df,col='timestamp'):\n",
    "    minutes = minutes * 60\n",
    "    df_list = []\n",
    "    while start < end:\n",
    "        cur_df = df[(df[col] >= start) & (df[col] < start+minutes)]\n",
    "        if len(cur_df):\n",
    "            df_list.append(df[(df[col] >= start) & (df[col] < start+minutes)])\n",
    "        start+=minutes\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37a5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Identifier'] = users['Identifier'].apply(lambda x : x if (len(x.split(\":\"))!=2) else x.split(\":\")[1])\n",
    "users.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f43fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With region\n",
    "# users['identity-event'] = \"source-\"+users['Identifier'] + \"|\" + users['eventName']\n",
    "# users['event-region'] = users['eventName'] + \"|\" + users['awsRegion']\n",
    "# users['region-target'] = users['awsRegion'] + \"|\" + \"target-\"+ users['TargetService']\n",
    "\n",
    "# Without region\n",
    "\n",
    "users['identity-event'] = \"source-\"+users['Identifier'] + \"|\" + users['eventName']\n",
    "users['event-target'] = users['eventName'] + \"|\" + \"target-\"+ users['TargetService']\n",
    "users = users[users['eventName'].notna()]\n",
    "\n",
    "# print(\"Number of nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e60c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22098b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['Identifier'] = users['Identifier'].apply(lambda x : f\"source-{x}\")\n",
    "users['TargetService'] = users['TargetService'].apply(lambda x : f\"target-{x}\")\n",
    "df_list = get_time_df(users['timestamp'].iloc[0],users['timestamp'].iloc[-1],60*60*24,users)\n",
    "for i in df_list:\n",
    "    print(len(i))\n",
    "# print(len(df_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = users.drop(columns=['Error'])\n",
    "df1 = t[t.isna().any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399080e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nodes(g,df,col,x,jump=10):\n",
    "    y = 10\n",
    "    unique_nodes = df[col].unique()\n",
    "    for i in unique_nodes:\n",
    "        if i!= None:\n",
    "            g.add_node(f'{i}',pos=(x,y))\n",
    "            y+=jump\n",
    "    for i in range(len(unique_nodes)-1):\n",
    "        g.add_edge(unique_nodes[i],unique_nodes[i+1])\n",
    "\n",
    "def add_edges(g,df,col):\n",
    "    edges = df[col].value_counts()\n",
    "    for node,value in edges.items():\n",
    "        start_node,end_node = node.split('|')\n",
    "        if \"None\" not in start_node and \"None\" not in end_node:\n",
    "            g.add_edge(start_node, end_node, weight=value)\n",
    "\n",
    "nodes = ['Identifier','eventName','TargetService']\n",
    "edges = ['identity-event','event-target']\n",
    "def generate_graph(G,df_nodes,df_edges):  \n",
    "    x = 10\n",
    "    for node in nodes:\n",
    "        add_nodes(G,df_nodes,node,x,100)\n",
    "        x+=1\n",
    "        \n",
    "#     for node in nodes:\n",
    "#         if node!='eventName':\n",
    "#             add_nodes(G,df,node,x,100)\n",
    "#         else:\n",
    "#             add_nodes(G,df,node,x,100)\n",
    "#         x+=10\n",
    "    # With region\n",
    "#     add_nodes(G,df,'awsRegion')\n",
    "#     add_edges(G,df,'identity-event')\n",
    "#     add_edges(G,df,'event-region')\n",
    "#     add_edges(G,df,'region-target')\n",
    "    # Without region\n",
    "    for edge in edges:\n",
    "        add_edges(G,df_edges,edge)\n",
    "        add_edges(G,df_edges,edge)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d70c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graphs(df,df_list):\n",
    "    li = []\n",
    "    for data in df_list:\n",
    "        G = nx.Graph()\n",
    "        generate_graph(G,df,data)\n",
    "        li.append(G)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4764013",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = generate_graphs(users,df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f0120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "for i,G in enumerate(graphs):\n",
    "    rcParams['figure.figsize'] = 14, 10\n",
    "    pos=nx.get_node_attributes(G,'pos')\n",
    "    # pos = nx.spring_layout(G, scale=20, k=3/np.sqrt(G.order()))\n",
    "    d = dict(G.degree)\n",
    "    nx.draw(G, pos, node_color='lightblue', \n",
    "            with_labels=True, \n",
    "            nodelist=d, \n",
    "            node_size=[d[k]*300 for k in d])\n",
    "    labels = nx.get_edge_attributes(G,'weight')\n",
    "    nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_size=5)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.savefig(f'{i}-plotgraph.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    pos=nx.get_node_attributes(G,'pos')\n",
    "    nx.draw(G,pos)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13547652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pylab import rcParams\n",
    "# rcParams['figure.figsize'] = 14, 10\n",
    "# pos=nx.get_node_attributes(G,'pos')\n",
    "# # pos = nx.spring_layout(G, scale=20, k=3/np.sqrt(G.order()))\n",
    "# d = dict(G.degree)\n",
    "# nx.draw(G, pos, node_color='lightblue', \n",
    "#         with_labels=True, \n",
    "#         nodelist=d, \n",
    "#         node_size=[d[k]*300 for k in d])\n",
    "# labels = nx.get_edge_attributes(G,'weight')\n",
    "# nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)\n",
    "# pos=nx.get_node_attributes(G,'pos')\n",
    "# nx.draw(G,pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2879f928",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_length = 20  # maximum length of a random walk to use throughout this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_stellar(graphs):\n",
    "    stellar_list = []\n",
    "    for G in graphs:\n",
    "        G = StellarGraph.from_networkx(G)\n",
    "        rw = BiasedRandomWalk(G)\n",
    "        stellar_list.append((G,rw))\n",
    "    return stellar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a4c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "SL = gen_stellar(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8936b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_walks_graphs(SL):\n",
    "    WW = []\n",
    "    for G,rw in SL:\n",
    "        weighted_walks = rw.run(\n",
    "          nodes=G.nodes(),  # root nodes\n",
    "          length=walk_length,  # maximum length of a random walk\n",
    "          n=10,  # number of random walks per root node\n",
    "          p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "          q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "          weighted=True,  # for weighted random walks\n",
    "          seed=42,  # random seed fixed for reproducibility\n",
    "        )\n",
    "        WW.append(weighted_walks)\n",
    "    return WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25342429",
   "metadata": {},
   "outputs": [],
   "source": [
    "WW = weighted_walks_graphs(SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = StellarGraph.from_networkx(G)\n",
    "# rw = BiasedRandomWalk(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca0ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_walks = rw.run(\n",
    "#   nodes=G.nodes(),  # root nodes\n",
    "#   length=walk_length,  # maximum length of a random walk\n",
    "#   n=10,  # number of random walks per root node\n",
    "#   p=0.5,  # Defines (unormalised) probability, 1/p, of returning to source node\n",
    "#   q=2.0,  # Defines (unormalised) probability, 1/q, for moving away from source node\n",
    "#   weighted=True,  # for weighted random walks\n",
    "#   seed=42,  # random seed fixed for reproducibility\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c14ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted_model = Word2Vec(\n",
    "#   weighted_walks, vector_size=128, window=5, min_count=0, sg=1, workers=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72085e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_models(WW):\n",
    "    w2v_models = []\n",
    "    for weighted_walks in WW:\n",
    "        weighted_model = Word2Vec(\n",
    "          weighted_walks, vector_size=128, window=5, min_count=0, sg=1, workers=1,\n",
    "        )\n",
    "        w2v_models.append(weighted_model)\n",
    "    return w2v_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443317cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model_list = weighted_models(WW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e89af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_embedding(weighted_model_list):\n",
    "    embedding = []\n",
    "    for weighted_model in weighted_model_list:\n",
    "        node_ids = weighted_model.wv.index_to_key  # list of node IDs\n",
    "        weighted_node_embeddings = (\n",
    "          weighted_model.wv.vectors\n",
    "        ) \n",
    "        embedding.append((node_ids,weighted_node_embeddings))\n",
    "    return embedding\n",
    "embedding = node_embedding(weighted_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f8231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_ids = weighted_model.wv.index_to_key  # list of node IDs\n",
    "# weighted_node_embeddings = (\n",
    "#   weighted_model.wv.vectors\n",
    "# ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, random_state=42)\n",
    "# weighted_node_embeddings_2d = tsne.fit_transform(weighted_node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c16624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2_graphs(embedding):\n",
    "    embedding2d_annotation = []\n",
    "    for node_ids,weighted_node_embeddings in embedding:\n",
    "        tsne = TSNE(n_components=2, random_state=42)\n",
    "        weighted_node_embeddings_2d = tsne.fit_transform(weighted_node_embeddings)\n",
    "        embedding2d_annotation.append((node_ids,weighted_node_embeddings_2d))\n",
    "    return embedding2d_annotation\n",
    "d2_graphs_list = d2_graphs(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a985965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "pos_list = []\n",
    "for node_ids,weighted_node_embeddings_2d in d2_graphs_list:\n",
    "    alpha = 0.7\n",
    "    #fig = plt.figure(figsize=(5,5))\n",
    "    #plt.subplot(1,len(files),num+1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(\n",
    "        weighted_node_embeddings_2d[:, 0],\n",
    "        weighted_node_embeddings_2d[:, 1],\n",
    "        #c=node_targets.cat.codes,\n",
    "        cmap=\"jet\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    di = {}\n",
    "    for i,txt in enumerate(node_ids):\n",
    "        plt.annotate(i, (weighted_node_embeddings_2d[i][0], weighted_node_embeddings_2d[i][1]))\n",
    "        print((i, (weighted_node_embeddings_2d[i][0], weighted_node_embeddings_2d[i][1])))\n",
    "        di[txt] = (weighted_node_embeddings_2d[i][0], weighted_node_embeddings_2d[i][1])\n",
    "    pos_list.append(di)\n",
    "    #plt.axis('off')\n",
    "    plt.title(file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614ebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "plt.show()\n",
    "for i,G in enumerate(graphs):\n",
    "    rcParams['figure.figsize'] = 14, 10\n",
    "#     pos=nx.get_node_attributes(G,'pos')\n",
    "    # pos = nx.spring_layout(G, scale=20, k=3/np.sqrt(G.order()))\n",
    "    d = dict(G.degree)\n",
    "    pos = pos_list[i]\n",
    "    nx.draw(G, pos, node_color='lightblue', \n",
    "            with_labels=True, \n",
    "            nodelist=d, \n",
    "            node_size=[d[k]*300 for k in d])\n",
    "    labels = nx.get_edge_attributes(G,'weight')\n",
    "    nx.draw_networkx_edge_labels(G,pos,edge_labels=labels,font_size=5)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.savefig(f'{i}-embedded-plotgraph.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    pos=nx.get_node_attributes(G,'pos')\n",
    "#     nx.draw(G,pos)\n",
    "        \n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be55fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de18f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(node_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b378238",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for _,weighted_node_embeddings_2d in d2_graphs_list:\n",
    "    clustering = DBSCAN(eps=1.5, min_samples=5).fit(weighted_node_embeddings_2d)\n",
    "    models.append(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef35fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clustering in models:\n",
    "    print(len(clustering.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46d304",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clustering in models:\n",
    "    print(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba01432",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clustering in models:\n",
    "    print(clustering.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e240135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "for li,clustering in zip(d2_graphs_list,models):\n",
    "    node_ids,weighted_node_embeddings_2d = li[0],li[1]\n",
    "    alpha = 0.7\n",
    "    #fig = plt.figure(figsize=(5,5))\n",
    "    #plt.subplot(1,len(files),num+1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.scatter(\n",
    "        weighted_node_embeddings_2d[:, 0],\n",
    "        weighted_node_embeddings_2d[:, 1],\n",
    "        c=clustering.labels_,\n",
    "        cmap=\"jet\",\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    for i,txt in enumerate(node_ids):\n",
    "        plt.annotate(clustering.labels_[i], (weighted_node_embeddings_2d[i][0], weighted_node_embeddings_2d[i][1]))\n",
    "        print((i, (weighted_node_embeddings_2d[i][0], weighted_node_embeddings_2d[i][1])))\n",
    "    #plt.axis('off')\n",
    "    plt.title(file)\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29838ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {0:node_ids}\n",
    "for i,clustering in enumerate(models,start=1):\n",
    "    di[i] = clustering.labels_\n",
    "df = pd.DataFrame(data=di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216cac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
